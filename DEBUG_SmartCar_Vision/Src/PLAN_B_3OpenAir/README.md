###
三个openair方案

基本步骤

1.提取蓝色背景最大范围
2.寻找蓝色背景反色块及是目标板
  (经测定除了少部分带有蓝底目标板识别不稳定外, 剩下目标板均可识别)

3.检测到有目标板存在即发送消息给主板往该方向移动
  (采用这个方案建议三个openair装在同一个横杆上并且装在前端[和电磁循迹杆差不多], 只需要平移即可[可能也需要盲移])

此文件夹当中后缀有0.1标识的为修改过固件的版本
后缀为0.0标识的为未修改过固件的识别版本

2024.2.15
添加CLASSIFY.py文件, 其中包含初步的自动化阈值追踪色块
自动化阈值基本步骤
初始化开启自动曝光
1. 获取LAB色域直方图
2. 根据LAB直方图获取B最小值为最低阈值
   取B的中位数为最大值
根据早上晚上测试结果以及测试了指定亮度[使用sensor.set_brightness()函数](100, 300, 500, 800, 1000， 1300， 1500)来看, 光照在暖色调也有很不错的表现,自动阈值基本可以避免光线变化对色块追踪的干扰, 有较强的鲁棒性。
但是在光线强度过强达1500以上时, 阈值追踪效果会变差, 噪声很难抑制
所以使用自动曝光函数来自动调节曝光, 降低光照强度, 降低阈值追踪的噪声

2024.2.23
添加函数文件improvedOTSU.py 以及参考文献 其中为改进版OTSU大津算法,
由于openart mini固件内置OTSU算法在直方图截取的方面有一定问题无法正常使用, 并且
由于部分openart mini无法刷入修改后的固件， 所以使用python脚本实现OTSU进行阈值分割
传统OTSU算法在不为C语言底层语言而作为python脚本实现其时间复杂度超出了预期范围
经过实测, 传统OTSU算法处理一次直方图信息为0.200秒左右差不多5帧左右不满足比赛实时性
而改进OTSU算法通过递归以及模糊阈值的截取, 只需要处理一部分的直方图信息, 大大降低
时间复杂度, 实测处理一次直方图信息为0.045秒左右差不多为20-22帧左右, 帧率稳定高效,
且分割精度较高, 满足比赛实时性要求
improvedOTSU基本思路
1. openmv内置api获取B通道直方图信息截取B通道最小值到B通道平均值区域的直方图信息
2. 预处理前景，背景的比例和均值
3. 遍历直方图，获取类间方差最大的为阈值
4. 由于阈值范围为0-255 重新映射回-128-127范围, 最后返回最终阈值


###